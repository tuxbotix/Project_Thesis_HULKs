\documentclass[english, printversion, nomenclature, notitle]{tuvisionthesis} % TUVISION template
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{cite}
\usepackage{cleveref}
\usepackage{gensymb}
\usepackage{graphicx}
\graphicspath{ {./images/} }

% use other format for captions
\usepackage[labelfont=bf,textfont=it]{caption}

\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\usetikzlibrary{arrows}
\usetikzlibrary{plotmarks}
\usepgfplotslibrary{external}
\tikzexternalize

\usepackage{listings} 
\lstset{language=C++}

\usepackage{xargs}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
%% Due to conflicts..
\usepackage{letltxmacro}
\LetLtxMacro{\oldtodo}{\todo}
\renewcommandx{\todo}[2][1=]{\tikzexternaldisable\oldtodo[#1]{#2}\tikzexternalenable}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

% correct appearance of calligraphic letters
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

% Information that appears on title page
\author{Adikari Appuhamillage Darshana Sanjeewan Adikari}
\title{Joint and Camera Calibration for NAO Robot}
\category{Project Thesis}
\preamblefile{Preamble}

% Main document
\begin{document}
% Title page
\hypersetup{
	pdfauthor=\@author\relax,
	pdftitle=\@title\relax
}
\tuvisionheading
\hypersetup{pageanchor=true}
\clearpage{\thispagestyle{empty}\cleardoublepage}

% Chapters
%%%% INTRO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

Robotics has evolved from caged industrial machines to aesthetically appealing and "smart" robots that aim to be friendly with humans. Their proposed roles range from being learning aids for children to caring the elderly and also to play soccer!.

The RoboCup was inaugurated 21 years ago (1997) in Japan as an annual competition in robotics with the vision of robots playing against FIFA champions in the year 2050. It also features  logistics and rescue categories, highlighting  the fact that robots should be able to handle complex environments opposed to highly structured industrial settings in order to successfully interact with humans in day-to-day life.  Since 2008, the Robocup SPL (Standard Platform League) has been using NAO, a 58cm tall humanoid robot by Softbank robotics.

This thesis presents the design, implementation and application of a Camera and Joint calibration process for the NAO, in the context of "HULKs", the SPL team of Hamburg University of Technology. Not only the technical challenges, but also factors like time to calibrate, logistics are also considered due to the varying venues and competitive nature of the world championship.

This thesis is organized as follows. \todo{Complete this}

\section{Problem Statement}

Calibrating the two cameras of the NAO has been a prerequisite for obtaining good coordination of the robots and several methods has been derived at HULKs for the purpose of Camera Calibration (Intrinsic and Extrinsic) \cite{HULKs2017Report}.

In recent years, with the ageing NAO V5 robots of the team, it was observed that NAO's joints exhibits significant amount of backlash. In certain occasions, the origin of joint position were also found to be shifted as much as 20 degrees. For a joint such as the neck, this means the error of perception is easily in the magnitude of several meters.

Therefore it has come to attention the need for automatic joint error detection and calibration as this also affects camera extrinsic calibration process.

In the past several teams has attempted automating this with less than satisfactory results and all known processes that appears to work well are manual methods. 

\subsection{Potential reasons for specified problems}
Prior to presentation of a solution, it is imperative to identify potential sources of failures experienced in past. Based on the available research, observations and practical experience with calibrating the NAO robots, following hypotheses are presented regarding causes for previous failures and difficulty in calibration.

\begin{itemize}
	\label{itemize:possible_reasons}
	\item Used calibration poses weren't optimal, resulting in incomplete coverage of the observable subspace (considering the joint error domain\todo{is this the right wording?}) which leads to poor calibration quality inclusing lack of convergence and local minimum exits.
	\item While a global minimizer could improve the results, it is still not immune from observation noise which can distort the cost function such that solved global minima is not the real one.
	\item As noted in B-Human's research, joint backlash plays a crucial role. Therefore, captures should also contain information about direction of backlash or limit the scope of calibration assuming the robot's usable poses always load joints in the ways resulting same backlash effects.
	\item Camera based calibration also depend on intrinsic and extrinsic parameters; The former can be calibrated without reliance of robot's positioning, but the latter depends on calibrated joints causing a cyclic dependency which can possibly be resolved by multiple cycles of calibration for joints and extrinsic parameters. This concern is already mentioned in Team Research Report of B-Human and their manual calibration procedure appears to address it in the above mentioned method.
\end{itemize}

\section{Goals}

The aim of this thesis is to develop a fully or semi-automatic joint and camera calibration. This includes theoretical observer modelling, optimal  pose generation and the implementation of necessary tools, modules into HULKs NAO framework and the debug tooling (which will be extending the current calibration tools).

Since item 1 and 2 of \cref{itemize:possible_reasons} are not covered well in most literature or only in industrial context (which use laser trackers), this thesis will pay more attention for importance of picking optimal poses, observability, reduction of ambiguities (somewhat inverse to coverage of observable subspace) \todo{use a section to define wording} and improving calibration optimizers. Finally the evaluation phase will be used to validate the hypotheses. A detailed 

Below listed is a summarized set of goals. A detailed workflow is presented in \cref{chap:workflow}.

\begin{itemize}
	\item Derive a process to determine suitability of a sensors, poses, input data, etc. This may include observation modelling.
	\item Investigate the suitability of onboard sensors based on the above mentioned process. (At least some of the joint errors should be correctable)
	\item Determine the effect of backlash and offsets, level of observation and other factors.
\end{itemize}

\section{Limitations \& Scope}

This research is performed with the following constraints.

\begin{itemize}
	\item Intrinsic Camera calibration is not considered, as it doesn't depend on joints. enabling it to function well even without the intended improvements of this research.
	\item Only on-board sensors are evaluated in this thesis, therefore Cameras will be the main source of information in addition to joint position sensors.
	\item Primary testing will be with different levels simulations.
	\item Optionally, perform real life testing with robots if and when simulation proves feasibility and there is enough time.
\end{itemize}

%%%% WORKFLOW %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Workflow \& Milestones}
\label{chap:workflow}

This chapter describe the goals in details in terms of milestones and the proposed workflow.  The methodology \cref{chap:methodology} is followed in this order.

\section{Initial preparations}
This step identify and fullfill the prerequicites.

\begin{enumerate}
	\item Determine which type of errors affect the accuracy of the robot.
	\subitem Joint backlash might be observable from joint angle sensors.
	\subitem Joint offsets cannot be directly observed from onboard sensors.
	\item Determine which poses the robot frequently use and how the errors affect.
	\item If backlash is not directly observed, a model is needed.
	\subitem Else; It can be assumed only joint offsets affect the kinematic chain.
\end{enumerate}

\section{Observation model}
In order to identify the ability of sensors under consideration and their observation capability of joint errors, developing  models is proposed.

\begin{enumerate}
	\item Define and observation model/ framework for joint and camera extrinsic error space.
	\subitem Some abstraction for obs. models are needed in order for transparent expansion with different sensors in future.
	\item Derive "poses" in which the calibration will take place. Due to trillions of possible joint configurations, a small subset of optimal poses has to be determined.
	\begin{itemize}
		\item Poses must be similar/ stimulate joints in similar manner to poses seen/ used during SPL games. Thus, stable, standing poses are preferred.
		\item Apply the observation model to each possible pose and obtain information such as magnitude and direction vector of observation space.
		\item Using above observation information and other weights, a cost function will be evaluated and "best" poses are chosen.
	\end{itemize}
\end{enumerate}

\section{Calibration Process}
The following tasks aim to derive a calibration process that will use poses obtained by the method proposed in the previous section.

\begin{enumerate}
	\item Make the robot reach each calibration pose, capture sensor values. (Cameras, joint angles, etc).
	\subitem the uniqueness of observation direction for each joint at a given pose highly influence quality/ possibility of observing joint error without much ambiguity. This will be further discussed in *state of art* and *methodology*
	\item Optimization to determine joint errors and camera extrinsic values.
	\item Based on results of simulation, real world tests can be done.
\end{enumerate}

\section{Testing and evaluation of calibration poses and process}

Evaluating the outcome of previous stages is done in multitude of manners.

\begin{itemize}
	\item Unit tests or similar tests to verify data storage, computational methods
	\item Simulated joint calibration testing with a dense set of captured data (3D-2D correspondences in case of camera) with a suitable population size.
	\subitem The goal is to verify calibration is possible to a high degree of confidence.
	\item Simulated testing with relatively sparse set of captured data. This would verify ability to use real world constraints such as using points off a calibration pattern at a given place. It gives a "sparse" data set compared to "dense" data sets taken by a large imaginary grid of points resulting potentially worse calibration despite faster optimization computation.
	\item If time permits, real world testing with actual NAO robots will be performed in the same manner as the previous method. The only challenge would be reliably obtaining ground truth.
\end{itemize}

\section{Timeline}
\todo{Complete this}

%%%% LIT REVIEW %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Literature Review}

\section{NAO Robot}

\subsection{Joints \& Coordinate frames}
NAO V5 and V6 have almost identical link lengths but the masses may be different. The joint actuators are explained in the datasheet, but they don't mention typical backlash values. \todo{cite, verify this}

These joints can be commanded at 100Hz rate, which is possible via NAOqi - a software component supplied by Softbank Robotics to actuate the joints and to read back sensor values.

\subsection{Sensors}
\subsubsection{Camera}
\todo{datasheet \& drawings}
NAO V5 has been the primary version used in the past few years which feature a camera with following specifications.

NAO V6 will be used officially in the upcoming RoboCup, thus it is also a priority to allow the calibration framework to be used with this platform. The cameras are upgraded to higher pixel density and they also feature autofocus (most probably be disabled).

\subsubsection{Joint encoders}
\label{subsub:jointEncoders}

They feature magnetic incremental encoders with $0.1\degree$ precision. As mentioned previously, these sensors give feedback to closed loop controllers of the joints as well as let the software framework to calculate kinematic matrices. \todo{cite datasheet}

\subsubsection{Other Sensors}
IMU is also an important element, FSR ... etc. \todo {complete this}

\subsection{HULKs NAO framework}
This is the software framework developed by HULKs for the NAO to play soccer in RoboCup SPL . It access robot's hardware through several software components provided by SoftBank Robotics. However it access cameras via kernel driver (V4L2). Due to this difference, two major threads are employed; Vision (+ brain -> perception \& behavior) and Motion. They cycle at 60Hz (30FPS per camera x 2) and 100Hz (rate set by NAOqi - the interface to access hardware). Due to this difference of rates, synchronization is done with a set of timestamped buffers. For calibration purposes, therefore static poses are desirable for capturing images and joint values to avoid time-synchronization induced shifts. \todo{cleanup}

The framework also supports debugging and configuration via the Debug tool "MATE" - also developed by HULKs. Further information is present in the Team Research Report. \todo{cite TRR}

This framework includes a module to compensate joint offset errors \todo{cite Code release?}. It offsets the joints movement commands by the given value and it also compensate this value from sensor output, making the robot's perception unaware of induced offsets. \todo{Maybe include a block diagram?}

\section{Camera calibration (extrinsic)}
Camera calibration is a well researched topic as it is a primary dependency for obtaining good results with camera systems. In this thesis, these standard methods \& tools for intrinsic calibration is employed, while discussion about extrinsic approaches will be given higher regard.

\subsection{Method of HULKs}

The calibration process is based on the debug tool used by HULKs (MATE) as well as the HULKs NAO framework. In summary, the calibration is achieved by capturing images and kinematic chain with time synchronization to solve the following system of equations .with a non linear solver (LM). The method of operation and usage is explained in detail in the team research report. \todo{cite HULKS TRR}

\subsection{Other teams}
The team B-Human employs a method combined with joint calibration \todo{ref section.. and paper}. HTWK-Lepzig employs a method based on the centre circle, their robots gather enough feature points in several poses to solve the non linear equation. Berlin United also employs a similar approach but they do this with the robots in a sit down (unstiffed) pose and they can use all the lines of the entire field as features.

\subsection{Calibration features}

In methods such as photogrammetry, a dense feature set is used to identify the relative position of the camera. In typical intrinsic calibration, a chessboard or similar pattern is used. For extrinsic calibration, the same can be used.

However, one disadvantage with the classic chessboard pattern is that the processing taken for identifying the corners are time consuming. ChAruco - a hybridization of the classic chessboard and AR markers to achieve fast detection and obtaining 3D points for partially visible patterns. ( Traditional implementations using chessboard relies on having complete visibility of the chessboard).  \todo{Improve this. Cite OpenCV Contrib papers. Include figures}

\section{Joint calibration}
This section discuss the fundamentals of Joint errors, reasons for calibration and possible approaches.

\subsection{Joint error types}
\todo{rewrite}
Two major types of joint errors contribute to adverse effects, they are backlash and shift of origin (which cause the joint actuator to point at physically incorrect locations although the sensors percepts otherwise). \todo{cite and find most appropriate terminology.}

Backlash occurs due to necessary gap between gears (to avoid jamming) and wear occurred due to usage. While precision machined gears with hardened surfaces operating with tribologically matched lubrication can minimize designed backlash and wear rate.However, such improvements doesn't appear to be available for the NAO as most of the joints feature plastic gears, multiple reduction stages and backlash of some joints in even brand new (Observed with V5 refurbished, V6 brand new) robots can be more than $1\degree$ . Therefore it can be concluded that effects of backlash is a major factor and thus possible methods to mitigate this problem has to be investigated.
\todo{add diagrams}

The errors caused by shifted sensor origin can happen due to mechanical shifting of the actuator relative to links and/ or physical shock damages (multiple such instances observed during RoboCup 2018 with head yaw joint).

The calibration can be rather straight forward if the position sensor of a joint can observe the effects of backlash, this means the sensor is connected between the two links the joint is comprised of. Assuming there is no play in rotary or linear axes, it should be possible to measure any backlash of this joint.

However complications arise if the backlash cannot be observed by the joint position sensor (encoder). In this case, a different sensor has to either directly observe the backlash or indirectly observe it by observing the aftereffects of such backlash (ie: change of actual position of end effector relative to base)\todo{add diagram}  In addition, when capturing data it has to be taken into account of the direction of backlash at a given pose (including if floating state). Once the direction of motion/ force is known, it is possible to compensate backlash by applying the appropriate offset - this is the procedure used in machining equipment with non-zero backlash leadscrews.

\todo{move this to methodology}
In the case of Nao in RoboCup SPL's context, it is possible to simplify the modelling as follows.
\todo{potential merge with proposed workflow?}
\begin{itemize}
	\item Determing if all joint backlash is observable
	\item if yes, then calibration can only be limited to joint offset errors as effects of backlash are directly measured.
	\item If not, then the calibration observations must be made in poses similar to what used in RoboCup
	\item Since almost all behaviour depends on bipedal motion and stability, it is safe to use only standing poses. 
	\item However to improve the accuracy of kicking, another set of separate observations maybe made and applied to identify effects of backlash for a lifted foot, then during the kick phase \todo{refer trr}, this special set of calibration angles can be introduced.
\end{itemize}
\todo{add diagrams}

\subsection{Direct measurement}

This approach is commonly used for lathes, milling machines and similar equipment with the use of dial indicators. While this is possible for the NAO as well, the "curvy" nature of the limbs (with almost no easily identifiable reference points) present a massive challenge in employing dial indicator based or similar approaches in a time efficient manner.

Another option is using an angle measuring tool or to 3D scan the joint at  two extremes of backlash at a given position and obtain the angle.\todo{Clean up this, possibly give some figures?} But this approach require more specialized equipment, processing power and possibly less portability. Yet this is a suitable method to obtain ground truth for the purpose of evaluating a particular calibration method. \todo{ references? }

\subsection{Indirect measurement}
Indirect measurement based methods are possibly more practical in the context of NAO robot, as they involve in less specialized sensors or eliminate need to measure each sensor individually.
\todo{citations?}
\subsection{Previous Work}

There are several experiments done in context of the NAO Robot for indirect joint calibration. Some involves fixing a calibration pattern in the form of a sticker [].. One of the experiments by the team B-Human involves "sandles" worn by the NAO, but ultimately their results were less than satisfactory. A few possible causes include the robot taking measurements while lying on its back which is not a typical pose during RoboCup games, thus the non-directly observable backlash affected the kinematic chain different to what would be observed had the robot being standing. \todo{add citation, add table with results} In addition, the authors also mention possible effect from flexing of the limbs and torque modelling would have improved their experiment based on the results by Nao Devils of TU Dortmund in modeling flexing and joint torque contributions. \todo{Read nao devils literature also}

Currently B-Human have a working joint calibration method based on manual observations. First, the robot is put to a specific pose (ie: standing), lifted to observe foot offsets and adjustments are done so that both feet are at same level and orientation. Next, the robot is placed on the ground and the distance to hip or another known joint origin is measured. This allows to measure the length of the kinematic chain of each leg. Any deviations are compensated by means of inverse kinematic values and finally the robot's leaning \todo{clarify} towards ground is also adjusted. While this appears to be a practical method, the disadvantage of manual measurements is time consuming and can be erroneous (measuring height to torso by a ruler would not be much accurate given lack of reference points on the NAO).

Several publications have covered the topic of choosing optimal poses (using condition number of the kinematic equation-matrix) for joint calibration when the end effector position is measured has claimed and seemingly proven that measurements from a small amount of optimal calibration poses yields better or equal results compared to using large amount of randomly chosen measurement poses. However, it should be noted that these publications were applied to industrial robots where the measurements were taken by accurate 3D measurement tools, whereas the preferred constraints for this thesis's use case provides further complications as the 2D cameras can only estimate the pose of a calibration target, not get a precise position.

There isn't significant amount of previous research regarding the observability of joint errors with on board sensors (esp. 2D cameras) alone. Therefore one of the key components of this thesis would be devising an observation model for joint errors and deriving most suitable poses. This should assist to explain the quality of calibration at each joint.

\section{Observation Models}
Considering the above revelations, observations and feedback gathered from discussions with other team members and teams, it was decided that deriving an observation model for joint errors for various available sensors (or fused outputs) would be beneficial than following a trial and error approach for calibration.

The basis of this observation model takes some of the inspiration from control systems where terms such as partial and full observability are defined. In this instance, the model tries to observe the difference of sensor measurements a joint error cause and the goal is to determine the poses that yield most observation strength. In order to do this fast and accurately, a software representation of the kinematic chain and camera is used, thus this modeling will be done in a simulated setting.

\todo{move to methodology}
This thesis will focus only on the on board cameras, but abstraction of this concept will make it possible to extend to other sensors as well.

\begin{itemize}
	\item First, a grid of 3D points are defined relative to Robot's origin. Due to the possibility of eliminating degrees of freedom, these points will always lie on the ground, thus one dimension is reduced in defining the positions.
	\item The robot will attain a pose generated by the program, section ... \todo{ref} explains this process more.
	\item Now these ground points are observed from the camera, in order to do this projectio, the robot's kinematic chain is used. The observed points on the camera image plane will be stored.
	\item Now a joint will be moved by a small amount, this would be considered as a "joint position error". Then similar to previous step, the ground points are observed again and correspondence of points with previous step are made.
	\item Due to availability of the correspondences, it is possible to obtain the movement of each point in terms of pixels and derive the motion of the camera from them. Simplest modeling would only consider X, Y translation and rotation in the Z axis. Repeat this process for all concerned joints.
	\item These observation values are referred as sensitivities in the c++ program, they are written into files for further inspection.	
\end{itemize}

With the above set of sensitivities per joint per pose, it is possible to sort and pick the poses with the strongest overall sensitivity.

\todo{Write more about how this is defined, how others have done it, etc}
\subsection{Ambiguities of observations}
\label{subsec:ambiguities}

Since there are 14 Joints in interest (excluding arms), but only 3 dimensions (simplest model) for the sensitivity in camera based joint error observation model (mentioned in above subsection), there is a high possibility that the sensitivity of multiple joints at a given pose have similar direction vector. This effect will be referred as "ambiguity" for the rest of this thesis.
 
This is a crucial element that can weigh into the success or failure of this experiment. Therefore, it is important to pre-determine the possible ambiguities of the observations. 

It is already possible to identify problem cases by knowledge in inverse kinematics and intuition. For an example, Knee, hip and ankle pitch together may end up causing ambiguities, the reason is possibility of attaining a given position with more than one possible joint configuration. This is a common case in robotics when there are more joints (that can cover one or more DOF) than degrees of freedom. In addition, the observation inaccuracies can further cloud the calibration solving.

The evaluation of similarity between two observation directions can be done in multiple ways, one option is cosine similarity. Another is to get difference and norm of it. Also it is possible to simply see if each dimension is close by some amount, etc. Reducing the similarity measure into one dimension has its appeal as it is easier to understand and write programs to handle this concept.

\todo{More literature and the conclusion to proposed workflow or methodology?}

\section{Computing a pose for a robot}
This section discuss approaches in deriving "poses" for the robot. In this context, generating a pose means obtaining appropriate joint angles or expressing a pose by means of feet positions relative to torso and head joint angles. (Arms are not moved, will be in 0deg position.)

\subsection{Forward Kinematics}

In this approach, the pose is directly defined in terms of joint angles. The kinematic chain is generated by means of forward kinematic equations.

The drawback is that when generating in a brute-force method, it is not possible to directly identify if this pose is safe, stable, etc (these calculations is better defined via kinematic matrices). Due to this nature it is also not possible to directly define a work envelope (the region which a robot's links can access).

Finally, such brute force approaches can easily end up with very large number of possible iterations to exhaust entire joint angle space even with 1 degree step size. (ex: 16~ joints, 90~ deg freedom, 1 deg step -> 90\^16 ) \todo{replace with actual calculation}

\subsection{Inverse Kinematics}

Inverse kinematic approach take the target pose in terms of feet and torso position relative to each other and head joint angles. Then inverse kinematics is applied for the two legs to obtain the corresponding joint angles. The arm angles are obtained by one of the predefined poses within HULKs framework (STAND pose \todo{cite code release?})

In conclusion, direct joint values cannot give a direct understanding of the robot's posture to a user while the dual is that the robot cannot directly understand it's supposed to be joint positions by means of kinematic matrices of feet relative to pose. \todo{is it correct to call this a dual?}

Since both formats are required for generation, storage and interfacing, appropriate C++ classes and serialization methods are deviced.

\todo{refer data type structure?}

\section{Cost functions and optimizers}

This section discuss the considered approaches to determine optimal (or set) of poses for a given set of conditions.

Considering the above description of Observation models, in the case of a model that can output the observability of joint errors, it is desirable to obtain the pose(s) that can give highest observability. This maybe further constrained by applying weights such as which joint get priority, etc.

In order to further clean up and organize these data, optimization approaches are needed.

\subsection{Cost functions and role in this regard}

In order to obtain an optimal solution for a problem with multiple criteria, and a set of input parameters, one of the common approaches is using a cost function.

The goal is to obtain the set of parameters that can minimize the output of the cost function (cost) under the given constraints (criterion). One possible formulation of a such cost function is as follows.

\todo{example cost function}
\todo{citations}

These approaches are used in many fields including optimal control, machine learning, etc.

\subsection{Optimization approaches}

In order to solve a cost function, one possible way is to try all valid values for the parameters - applying the entire configuration space.

This approach is known as brute force, as the name suggests the method isn't "smart" or efficient. In order to cut back optimization time, various solvers exist to speed up the process. They usually employ gradient of error, sum of error squared and combinations.

Out of these optimizers, one class is global optimizers - they will attempt to find the best solution within the entire configuration space. For example, brute force method can do this as it explore the entire space. While the prospect of getting the best value is tempting, global solvers are computationally expensive, thus local methods are favoured when there is a good initial guess. There are also various approaches to speed up solving of global optimization problems including multi-agent, flood fill, etc methods. 
\todo{cite cite cite!!!}

Local optimization methods will find the closest minima (or maxima, depends on the approach) to the starting point. there is no guarantee it is the best solution. Thus the initial guess plays a major role. Levenberg Marquardt is one such popular solver/ optimizer algorithm.

\todo{cite, maybe also put some graphs?}

\subsection{Curse of dimensionality}
This is a phenomena mentioned in the field of data science where the data set involve high amount of or when the cost function has large number of parameters.

Due to the high dimensionality, it is not only difficult to visualize, but also difficult to compute and to clearly understand for a human. In addition, certain optimization methods are not suitable for high dimensional problems \todo{cite}

%%%% METHODOLOGY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Methodology}
\label{chap:methodology}
This chapter describe the methodology followed in this thesis. It is based on the workflow described in chapter \cref{chap:workflow}

Majority of the time was spent for pose generation and filtering stage due to the massive amounts of computation needed. The frame working for reaching robot poses was already done. \todo{write clearly}

\section{Initial work}

This stage was covering the prerequites.

\section{Generation of Calibration poses}
This phase became a major segment of this project due to the importance of finding out the poses that could get best results as calibration data captures. About 80\% of the implementation was dedicated for this matter.

\subsection{Software implementation}

Several sets of software were implemented for this research. One portion was within the NAO to obtain images and to get joint angles after a being stable. The next is user interface (within debug tool) to command robots to reach a pose and the nessesary calculation stage within the NAO.

The crucial set of software was in the pose generation and optimal pose finding stage. This was a set of C++ programs that depends on the HULKs NAO framework (TUHHSDK segments to be precise) to access existing kinematic, center of mass calculations as well as camera matrix and related calculations. In addition a multitude of classes were implemented to store data in text files with space seperated fields, with full serialization and deserialization capability to simplify IO operations. The following classes could be streamed into files and thus be persistantly stored.
\todo{More about data types.mayve a subsubsection?}
\todo{UML? flowcharts?}
\subsection{Pose Generation and initial filtering}

Initially, the forward kinematics approach was considered. \todo{tag the section}However due to billions of possible joint angle configurations and the lack of "direct understanding" about a given pose (position of feet, torso, etc), this approach was further disadvantagous to use.

Inverse kinematics base approach accepts the following parameters:
\begin{itemize}
	\item Support foot - left, right or double foot
	\item Torso pose relative to support foot (position \& rotations)
	\item Pose of the other foot relative to support foot
	\item Head yaw and pitch angles
\end{itemize}
This approach is somewhat complicated by the need to use inverse kinematics and it was observed a given pose is not achieved by inverse kinematics (as opposed to generating a pose directly from joint angles). Thus further checks were needed to verify the generated pose is actually similar to the desired pose.

\todo{equations?}
In either of the approaches, the final output is joint angles. Then these angles are used to verify whether the robot is in a stable stand-up posture.

This is done by checking if robot's COM projection to ground plane is within the support polygon. Thus in case of single foot support (support foot on the ground, and other foot raised), the support polygon is the polygon comprised of portion of NAO's foot touching the ground. In case of double foot, it's the polygon containing both feet and the region between them. \todo{refer support poly. literature}

Another verification added later was to confirm that the two legs does not collide with each other. The logic is based on Softbank's implementation of self-collision avoidance as explained in \todo{reference to softbank self-collision}.

If a pose pass both these checks, then it'll be appended into a file in a predefined format which is (de)serializable from the C++ program. \todo{refer to appendix?}

\subsection{Observation Model}
\todo{Complete this, explain better, figures...}
In context of this project, the most important criteria of selecting a pose is based on the observability of small joint movements by the available sensors. Each of these sensors are modelled as an observation model, thus it is possible to examine the strength and direction of observable dimensions of each sensor at a given pose by reaching that particular pose and inducing small joint movements (mimicking possible joint errors).

For the scope of this project, only the two cameras onboard the NAO robot were modelled. In addition, assumptions were made regarding the placement of calibration patterns.

\subsubsection{Camera observation model}
\todo{diagram of grid projection, etc stuff}

This model is comprised of following elements, it's state is updated whenever a new pose is submitted. \todo{ Merge with lit reviews section?? Or get it to here?}
\begin{itemize}
	\item CameraMatrix object (\todo{refer NAO architecture?}).
	\subitem This stores intrinsic as well as camera-to-ground matrix.
	\item Ground grid. This is a grid of points on the ground plane.
	\subitem The grid moves so that it is observable by each camera when the model is updated.
	\item Support foot, observable joints (for each camera and at each support foot). \todo{explain why single leg support is useful.}
	\item The observation space of small movement by the camera's sensor (2D) is assumed to be X, Y translations and Z rotations.
	\subitem Although six degrees of freedom is possible to be observed by a camera using two images or point-to-point correspondence sets, in practice, only x, y translations and z- rotation was dominant. \todo{how did I determine this? :P } Thus this is a simplification of the actual system.
\end{itemize}

The process of obtaining observability of a given pose for each joint is as follows: \todo{write as psuedocode?}
\begin{itemize}
	\item The CameraMatrix is updated based on the set of joint angles and support foot (Mentioned as "Raw Pose" in the code).
	\item Translate + Rotate the ground grid so that the camera can see the grid.
	\item Obtain projection of the ground grid in Camera image plane (2D). This is referred as "baseline points".
	\item For-each joint, add a \(\delta\theta\) angle and obtain projection of the ground points in Camera image plane (2D).
	\subitem Using correspondence of the baseline points and latter obtained points, the movement of camera sensor plane (x, y, rotation in Z axis) is obtained using an optimization method and stored.
	\item At the end of evaluation, an object comprising of observation values as well as whether movement of a joint was observed is returned.
\end{itemize}

\todo{NAO camera chain from ground..}

\subsubsection{Extending Observation model}

Based on the technique employed for the camera model, it is possible to model other sensors as well. The inputs would be joint angles, support foot and information of observable joints by the given sensor.
Output would be similar to camera observation output, in fact the same type of object can be returned albeit a possible different number of observed dimensions. Usage of C++ templates made this possible without unnecessary usage of inheritance traits. \todo{ rewrite clearly}

Once the sensitivities for a pose is returned for each sensor under consideration, they are written to a file with pose ID (generated in the previous step), sensitivity values for each joint. 
\subsection{Criteria for evaluating observability}

When a series of measurements is organized in the form of a vector, it gives the possibility to understand if two sets of measurements are "nearby", or at same direction, etc. \todo{maybe move this to lit-review?}

By applying this ability, it is possible to conclude if two observations are "similar". Thus if two (or more) observations for different joint movements at the same base pose is similar, there exist an ambiguity, as it isn't possible to separately identify which joint caused the particular observation. Thus avoiding poses with such similar observations for multiple joints is beneficial as the solving the equations by means of iterative solver needs as much as orthogonality between observation vectors as possible.
\todo{ Back up this with facts? dummy dtaa set? }

\subsection{Extracting optimal poses}

Considering the above mentioned need for dissimilar observation vectors for each joint observation for a given pose, and other factors, it was evident that filtering the poses with a cost function would be beneficial. 

However, once the evaluation was performed \cref{subsec:simGroundTest}, it was noticed that the rate of local minima convergence was high (70\% approx). Therefore an alternative or an improvement over the cost function method was needed to list a set of poses that complement the observation capabilities of each other. This approach is presented in \cref{subsec:posepose}.

\subsubsection{Cost function \& weights}
\label{subsec:costFunc}

\todo{define the cost function and other info}
\todo{ Explain the situation of angle}

\subsubsection{Pose-Pose interaction based sorting}
\label{subsec:posepose}

As explained in the section about ambiguities \cref{subsec:ambiguities}, multiple error configurations can have the similar observation from the camera, thus there will be multiple error configurations which can lead to low ($\pm2px$) average reprojection error, causing the solver to converge at a local minima. The aim of the above cost function was to choose poses that have minimum amount of joint observation ambiguities. However, one major problem of this approach was that it only considered the joint observation interactions within a pose. Since it did not consider if two poses have similar set of joint observation ambiguities, choosing a sample of "best" poses from this cost function did not yield good results as shown in \cref{subsec:simGroundTest}.

Therefore, a method to formulate the ability to the ambiguities of different poses was nessesary. The following terminology is introduced and then the process is detailed.
 
 \begin{enumerate}
 	\item joint-joint interaction vector: This vector contains the angle obtained from cosine similarity comparison mentioned in \cref{subsec:costFunc} for each joint-joint comparison. This was a later addition to PoseCost struct.
 	\item pose-pose interaction vector: This vector is of same size as joint-joint interaction vector. This contains values which indicate if the poses under consideration can complement joint-joint interaction case. Ideally, this value will be 0 meaning the two poses don't have similar ambiguity issue for the same pair of joints.
 	\item Interaction count: this value indicate how many non-complementing cases are there for a pose-pose interaction or joint-joint interaction. Ideally this should be 0.
 	\item pose-pose interaction cos: Similar in concept to joint interaction cost, it is the sum of above mentioned pose-pose interaction vector.
 \end{enumerate}



\todo{define the cost function and other info}
\todo{ Explain the situation of angle}

\subsubsection{Determining calibration pattern position}
\todo{Not implemented yet}

\section{Calibration Process}
A modified version of the RC2018 calibration tool is used for this step. In exact terms, the ability to feed poses, workflow and internals of the calibration pipeline was altered.

Further information about the tools and software is available in the team research report and the code release. \todo{cite when TRR is released}

%%\section{Testing and evaluation of calibration poses and process}

%%%% TESTING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Testing and Evaluation}
\todo{Intro para}
\section{Tests for code quality}
\todo{Mention unit tests, etc}
\section{Calibration tests}
\todo{Intro para}
\subsection{Simulation: Entire ground plane as a calibration pattern}
\label{subsec:simGroundTest}
In this phase, the same concept of a the grid of ground points mentioned in the observation model is used. The process is as follows.

\todo{Replace this with psuedocode listing}
\begin{itemize}
	\item Generate a grid of ground points.
	\item Generate a set of error configuration and for each;
	\begin{enumerate}
		\item Capture the ground points with the simulated Nao world-robot model and obtain the corresponding 2D points in camera plane for each pose. Only a small set of poses were under test (10).
		\item Use a solver to obtain joint calibration value that can minimize the reprojection error for the above correspondance set.
		\item Return the state of calibration (by solver), residual in camera plane (reprojection error vector), joint parameter residual.
		\item If the reprojection error is within a certain margin, it is considered as a success.
		\item However, the joint parameter residual is used to verify if the solver was stuch in a local minima.
	\end{enumerate}
	\item Accumilate all the residuals and compute the histograms.
\end{itemize}

\subsubsection{Error Generation}
For this evaluation, only poses that make the robot stand in one leg was used, thus it was focussed either left foot or right foot as support foot. Therefore, only the following joints were employed to generate the error configurations.

\begin{itemize}
	\item Head Yaw
	\item Head Pitch
	\item Support leg HipYaw joint
	\item .. to support leg Ankle Roll (6 joints per leg)
\end{itemize}
Support leg can be either left or right.

Based on the observations in \todo{cite bhuman paper}, the maximum error was determined to be $5\degree$. Since the "population size" is very large (ie: $100^8$ assuming $0.1\degree$ granularity and $\pm5\degree$ range per joint), a sample size of 10000 was selected. The sample set was generated using random numbers obtained from a generator with uniform distribution (\lstinline{std::uniform_real_distribution<float>}). Floating point random numbers in range $\pm5\degree$ were inserted for each of above joint. 

\subsubsection{Solvers}

Although it was planned to use global optimizers from the beginning, due to prior experience and intuition; yet the appeal of very fast convergence of Levenberg-Marquardt (often in a few iterations - under $100ms$) and abundance of high quality implementations caused the author to start with this algorithm. The implementation available with Eigen library was used (Eigen/unsupported).

\subsubsection{Local Minima problems}
It was noticed that while reprojection error was low ($\pm3 pixels$ approx), the residual of joint parameters had values as large as maximum error possible. Further inspection of induced error values vs the parameters given by the solver, it was determined that the solver got stuck at local minimums. This was considered as a failure and the rate was about 60-70\%.

\subsubsection{Global optimization attempts}
Since the failure rate with the local optimizer was unacceptable, attention for possible global optimization strategies was given. The author briefly tried the following approaches.
\begin{itemize}
	\item dlib::find\_min\_global(). \todo{cite}
	\item igl::pso (Particle Swarm Optimization). \todo{cite?}
	\item Stochastic initial guess with local optimizer, retried upto a given amount.
\end{itemize}

The first approach sometimes converged but the results were generally inferior to Levenberg Marquardt algorithm (when it converged) and was more slower (it was a non-derivative based solver). Next candidate was particle swarm optimization, it almost never had any convergence, thus a full test run was not attempted.

Finally, the idea of attempting to supply a sample set of the population as initial guess was formulated using uniform distribution based generation similar to the above mentioned error generation. Upon later reading, this approach appears to be similar to stochastic steepest descent, except the stochastic input is fed into Levenberg-Marquardt hoping the input helped to escape the local minima(s). \todo{literature?}

\subsubsection{Results}

Below are the results for each step of the above experiment.  

\begin{itemize}
	\item Grid size: 50 per side, $5cm$ between two points. ($2.5m$ per side)
	\item Camera image size: $640 x 480$ pixels. (Floating point arithmetic used for projections to reduce errors)
	\item Random distribution: Uniform Random Distribution.
	\item Sample size: 10000 error configurations
\end{itemize}

\begin{table}[]
	\begin{tabular}{|l|l|l|l|l|}
		\hline
	Distribution (Uniform) Range & Lev.-Mar.  & dlib::global & igl::PSO & stochastic \\
	\hline
	$\pm6.5\degree$& 13\% &  &  & 1.9\% \\
	$1\degree$ to $6.5\degree$ and $-1\degree$ to $-6.5\degree$	& 54\% & . &  &3.2\% \\ \hline
%		&  &  &  &  \\
%		&  &  &  & 

	\end{tabular}
\caption{Failure rates for solvers tested. Lev-Mar - Levenberg-Marquardt, dlib::global..., igl::PSO - Particle Swarm Optimizer in libigl, stochastic - random start positions with Lev.-Mar. solver. The reason for avoiding $\pm1\degree$ in second distribution is to eliminate effect of $0 - 0 = 0$ on the errors, thus artificially inflating the percieved quality of calibration.}
\end{table}
\todo{Figure... demonstrate it is not affected by tis}

\begin{center}
  \noindent\makebox[\textwidth]{\includegraphics[width=0.9\paperwidth]{"poselist-L-generic-L-LegaAndHeadUniRandErr0-6_5deg-pitchDiv2_stochastic_fix"}}
	\captionof{figure}{Error distribution for $\pm6.5\degree$ error set. Top row is before calibration and Bottom row is after calibration.}
\end{center}


\todo{Explain why}
\todo{Data, randomly induced errors, individually induced errors}
\subsection{Simulation: Actual calibration process}
\todo{Explain why}
\todo{Data, randomly induced errors, individually induced errors}
\subsection{Real?: Actual calibration process}
\todo{if above succeed, try on real robots}

\subsection{discussion}

%%%% CONCLUSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and future work}
\todo{Complete this}
%%% include your text here %%%
\bibliographystyle{splncs03}
\bibliography{bibliography}{}
\end{document}
