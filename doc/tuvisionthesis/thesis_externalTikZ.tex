\documentclass[english, printversion, nomenclature, notitle]{tuvisionthesis} % TUVISION template
\usepackage{amsmath}
\usepackage{tikz}

% use other format for captions
\usepackage[labelfont=bf,textfont=it]{caption}

\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\usetikzlibrary{arrows}
\usetikzlibrary{plotmarks}
\usepgfplotslibrary{external}
\tikzexternalize

\usepackage{xargs}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
%% Due to conflicts..
\usepackage{letltxmacro}
\LetLtxMacro{\oldtodo}{\todo}
\renewcommandx{\todo}[2][1=]{\tikzexternaldisable\oldtodo[#1]{#2}\tikzexternalenable}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

% correct appearance of calligraphic letters
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

% Information that appears on title page
\author{Adikari Appuhamillage Darshana Sanjeewan Adikari}
\title{Joint and Camera Calibration for Nao Robot}
\category{Project Thesis}
\preamblefile{Preamble}

% Main document
\begin{document}
% Title page
\hypersetup{
	pdfauthor=\@author\relax,
	pdftitle=\@title\relax
}
\tuvisionheading
\hypersetup{pageanchor=true}
\clearpage{\thispagestyle{empty}\cleardoublepage}

% Chapters
\chapter{Introduction}
\todo{Re-write this}
Robots are increasingly becoming human-friendly and humanoid robots are already considered for roles from learning tools for children to caring the elderly to play soccer.

The RoboCup was initiated in 1997 as an annual competition in robotics with main focus on playing Soccer.

This thesis is written regarding calibrating Nao, the humanoid robot by Softbank robotics. While the research presented here can be applied to other humanoid and serial robot platforms, the foundations lies in the context of RoboCup, where the team HULKs from Hamburg University of technology (TUHH) participate in the Standard Platform League. In addition to the technical challenges in calibration, the international and competitive nature of robocup also make it nessesary to consider factors like time to calibrate, logistics. 

This chapter will introduce more about the robocup, the Nao robot and the motivations for this thesis.

\section{Robocup}

With the vision of robots playing against FIFA champions in the year 2050, the Robocup was inaugurated 21 years ago (1997) in Japan. Currently the tournament hosts multiple leagues of humanoid robot soccer, but also hosts competitions in other areas such as logistics and rescue. The specialty of Robocup is that not only it is a competition, but it also act as a platform to share research, ideas and implementations (source code, etc) in robotics.

\subsection{The standard Platform League}

The RoboCup Standard Platform League comprise of teams playing against each other using the same type of Hardware. Initially the Sony Aibo robot "dog" was used as the platform and since 2008, the Nao Robot - a Humanoid robot from Softbank Robotics is used. 

\section{The Nao Robotics system}

\todo{Complete this}

\section{Motivation}

Calibrating the two cameras of the nao has been a prerequistic for obtaining good coordination of the robots and several methods has been derived at HULKs for the purpose of Camera Calibration (Intrinsic and Extrinsic).

In the recent years, with the aging Nao V5 robots it was observed that the joints of the Nao have a significant play and backlash. In certain occasions, the origin of the joint position sensors were also found to be shifted as much as 20 degrees. For a joint such as the neck, this means the error of perception is easily in the magnitude of several errors.

Therefore it has come to attention the need for automatic joint error detection and calibration as this also affects the camera extrinsic calibration process.

In the past several teams has attemped this with less than satisfactory results and as far as it is known, the only working process seems to be manual measurement and adjustment.

\section{Goals}
\todo{cleanup}
The aim of this thesis is to develop a fully or semi-automatic joint and camera calibration. This includes theoritical observer modelling, optimal calibration pose generation, calculation of potential success of calibrating a given joint and the implementation of the nessesary tools, modules into the HULKs Nao framework and the debug tooling (which will be extending the current calibration tools).

Investigate current approaches and determine issues with them

\begin{itemize}
	\item Derive a process to determine suitability of a sensors, poses, input data, etc. -> also observer model
	\item Investigate the suitability of onboard sensors based on the above mentioned process. (at least some joints must be calibrate-able)
	\item Determine the effect of backlash and offsets, level of observation and other factors.
\end{itemize}

However, it should be noted that the primary goal of this thesis is to provide a foundation on observer models, deriving them and a process to determine suitability, Not to calibrate robots to perfection as end result.**

\section{Scope}

Due to the vast number of possible avenues and requirements, this thesis is constrained in the following scope.

\begin{itemize}
	\item Only on-board sensors are evaluated in this thesis
	\item Primary testing will be with different levels simulations.
	\item Once simulation based testing proves feasibility, use real robots.
\end{itemize}

\section{Problem Specification}
\todo{Merge this with motivation}
\begin{itemize}
	\item Joint offsets and errors, (caused by Joint wear, etc)
	\item Camera extrinsic calibration is also affected by joint errors due to dependency of the kinematic chain.
	\item Manual methods not reliable/ not repeatable.
	\subitem It is demonstrated in multiple occasions that manual extrinsic calibration is time consuming.
	\subitem In addition, determining joint errors by manual inspection is error prone.
	\item It is not known in a deterministic manner whether onboard sensors are sufficient for joint and camera calibration of this scale.
\end{itemize}

\section{Requirements}  %% part of intro?
\todo{Merge this with Goals}
\begin{itemize}
	\item Investigate current approaches and determine issues with them
	\item Derive a process to determine suitability of a sensors, poses, input data, etc.
	-> also observer model
	\item Investigate the suitability of onboard sensors based on the above mentioned process. (at least some joints must be calibrate-able)
	\item Determine the effect of backlash and offsets, level of observation and other factors.
\end{itemize}

\section{Scope}  %% part of intro?

\begin{itemize}
	\item Only on-board sensors are evaluated in this thesis
	
	\item Primary testing will be with different levels simulations.
	
	\item Once simulation based testing proves feasibility, use real robots.
\end{itemize}

The goal of this thesis is to provide a foundation on observer models, deriving them and a process to determine suitability, Not to calibrate robots to perfection as end result.

\chapter{State of the art}

\section{Nao robot, joints, sensors}
\todo{Complete this, maybe merge with info at introduction?}
\subsection{Software framework}
\todo{Complete this}

\section{Camera calibration (extrinsic)}
Camera calibration is a well researched topic as it is a primary dependency for obtaining good results with camera systems. In this thesis, these standard methods \& tools for intrinsic calibration is employed, while discussion about extrinsic approaches will be given higher regard.

\subsection{Method of HULKs}

The calibration framework is based on the debug tool used by HULKs and the method of operation and usage is explained in detail in the team research report. In summary, the calibration is achieved by capturing images and kinematic chain with time synchronization to solve the following system of equations .with a non linear solver (LM).

\subsection{Other teams}
The team B-Human employs a method combined with joint calibration \todo{ref section.. and paper}. HTWK-Lepzig employs a method based on the center circle, their robots gather enough feature points in several poses to solve the non linear equation. Berlin United also employs a similar approach but they do this with the robots in a sit down (unstiffed) pose and they can use all the lines of the entire field as features.

\subsection{Calibration features}

In methods such as photogammametry, a dense feature set is used to identify the relative position of the camera. In typical intrinsic calibration, a chessboard or similar pattern is used. For extrinsic calibration, the same can be used.

However, one disadvantage with the classic chessboard pattern is that the processing taken for identifying the corners are time consuming. Also majority of openly available algorithms depends on full visibility of the pattern.
\todo{Improve this. Cite OpenCV Contrib papers. Include figures}
Charuco - a hybridization of the classic chessboard and AR markers to achieve fast detection and obtaining 3D points for partially visible patterns. ( Traditional implementations using chessboard relies on having complete visibility of the chessboard).

\section{Joint calibration}
\todo{Introduce..}
\subsection{Joint error types}
Two major types of joint errors contribute to adverse effects, they are backlash and shift of origin (which cause the joint actuator to point at physically incorrect locations although the sensors sense otherwise).

Backlash occurs due to nessesary gap between gears (to avoid jamming) as well as wear occured due to usage. While precision machined gears with hardened surfaces operating with tribologically matched lubrication types can minimize designed backlash and wear rate, this isn't noticeable in case of the Nao as most joints feature plastic gears, multiple reduction stages and the backlash of some joints of even brand new (Observed with V5 refurbished, V6 brand new) robots can be more than one degree. Therefore it can be concluded that the effects of backlash is a major factor and thus possible methods to mitigate this problem has to be investigated.

The errors caused by shifted sensor origin can happen due to mechanical shift of the actuator and/ or physical shock damages (multiple such instances observed during RoboCup 2018 with head Yaw joint).

\subsection{Direct measurement}

This approach is commonly used in lathes, milling machines and similar equipments with the use of dial indicators. While this is possible for the Nao as well, the "curvy" nature of the limbs present a massive challenge in employing dial indicator based approaches in a time efficient manner.

Another option is using an angle measuring tool or to 3D scan the joint at  two extremes of backlash at a given position and obtain the angle.\todo{Clean up this, possibly give some figures?} But this approach require more specialized equipment, processing power and possibly less portability. However this is a suitable method to obtain ground truth for the purpose of evaluating a particular calibration method. \todo{ references? }

\subsection{Indirect measurement}
Indirect measurement based methods are possibly more practical in the context of Nao robot, as they involve in less specialized sensors or eliminate need to measure each sensor individually.

\subsection{Previous Work}
There are several experiments done in context of the Nao Robot for indirect joint calibration. Some involves fixing a pattern in the form of a sticker \todo{Cite} The experiment by the team B-Human involves "sandles" worn by the Nao, but untimately their results were less than satisfactory. A few possible causes include the robot taking measurements while lying on its back which is not a typical pose during robocup games.\todo{Cite} However, they are using a manual observation based calibration method (including lifting the robot to observe foot offsets) rather successfully\todo{cite**}. The disadvantage of this method is the lack of automation and the time consuming nature of it.

In addition, there isn't much previous research regarding the observability of joint errors with on board sensors alone. Therefore one of the key components of this thesis would be devising an observation model for joint errors and deriving most suitable poses.

\section{Observation Models}
Considering the above revelations, observations and feedback gathered from discussions with other team members and teams, it was decided that deriving an observation model for joint errors for various available sensors (or fused outputs) would be beneficial than blindly attempting to calibrate based on a hypothesis.

\todo{Write more about how this is defined, how others have done it, etc}
\subsection{Ambiguities of observations}
This is a crucial element that can weigh into the success or failure of this experiment. Therefore, it is important to pre-determine the possible ambiguities of the observations. This is evaluated by computing cosine similarity of observations made for various joints at the same pose. \todo{More literature and the conclusion to proposed workflow or methodology?}

\section{Computing a pose for a robot}
\todo{Complete this}
\subsection{Forward Kinematics}
\todo{Complete this}
\subsection{Inverse Kinematics}
\todo{Complete this}

\section{Cost functions, Optimization, clustering}
\todo{Complete this}
\subsection{Cost functions and role in this regard}
\todo{Complete this}
\subsection{Optimization approaches and clustering}
\todo{Complete this}
\subsection{Curse of dimensionality}
\todo{Complete this}

\chapter{Proposed Workflow}
\todo{Intro para}
\section{Initial work}
\todo{Intro para.?}

\begin{enumerate}
	\item Determine which type of errors affect the accuracy of the robot.
	\subitem Joint backlash might be observable from joint angle sensors.
	\subitem Joint offsets cannot be directly observed from onboard sensors.
	\item Determine which poses the robot frequently use and how the errors affect.
	\item If backlash is not directly observed, a model is needed.
	\subitem Else; It can be assumed only joint offsets affect the kinematic chain.
\end{enumerate}
\section{Observation model and calibration poses}
\todo{Intro para?}
\begin{enumerate}
	\item Define and observation model/ framework for joint and camera extrinsic error space.
	\subitem Some abstraction for obs. models are needed in order for transparent expansion with different sensors in future.
	\item Derive "poses" in which the calibration will take place. Due to trillions of possible joint configurations, a small subset of optimal poses has to be determined.
	\begin{itemize}
		\item Poses must be similar/ stimulate joints in similar manner to poses seen/ used during SPL games. Thus, stable, standing poses are preferred.
		\item Apply the observation model to each possible pose and obtain information such as magnitude and direction vector of observation space.
		\item Using above observation information and other weights, a cost function will be evaluated and "best" poses are chosen.
	\end{itemize}
\end{enumerate}
\section{Calibration Process}
\todo{Intro para?}
\begin{enumerate}
	\item Make the robot reach each calibration pose, capture sensor values. (Cameras, joint angles, etc).
	\subitem the uniqueness of observation direction for each joint at a given pose highly influence quality/ possibility of observing joint error without much ambiguity. This will be further discussed in *state of art* and *methodology*
	\item Global optimization to determine joint errors and camera extrinsic values.
	\item Based on results of simulation, real world tests can be done.
\end{enumerate}

\section{Testing and evaluation of calibration poses and process}
\todo{Complete this??}

\chapter{Methodology}
\todo{Intro para}

\section{Initial work}
\todo{Complete this}
\section{Generation of Calibration poses}
This phase became a major segment of this project due to the importance of finding out the poses that could get best results as calibration data captures. About 80\% of the implementation was dedicated for this matter.

\subsection{Software implementation}
\todo{Complete this}
\subsection{Pose Generation and initial filtering}

Initially, the forward kinematics approach was considered. \todo{tag the section}However due to billions of possible joint angle configurations and the lack of "direct understanding" about a given pose (position of feet, torso, etc), this approach was further disadvantagous to use.

Inverse kinematics base approach accepts the following parameters:
\begin{itemize}
	\item Support foot - left, right or double foot
	\item Torso pose relative to support foot (position \& rotations)
	\item Pose of the other foot relative to support foot
	\item Head yaw and pitch angles
\end{itemize}
This approach is somewhat complicated by the need to use inverse kinematics and it was observed a given pose is not achieved by inverse kinematics (as opposed to generating a pose directly from joint angles). Thus further checks were needed to verify the generated pose is actually similar to the desired pose.

In either of the approaches, the final output is joint angles. Then these angles are used to verify whether the robot is in a stable stand-up posture.

This is done by checking if robot's COM projection to ground plane is within the support polygon. Thus in case of single foot support (support foot on the ground, and other foot raised), the support polygon is the polygon comprised of portion of Nao's foot touching the ground. In case of double foot, it's the polygon containing both feet and the region between them. \todo{refer support poly. literature}

Another verification added later was to confirm that the two legs does not collide with each other. The logic is based on Softbank's implementation of self-collision avoidance as explained in \todo{reference to softbank self-collision}.

If a pose pass both these checks, then it'll be appended into a file in a predefined format which is (de)serializable from the C++ program. \todo{refer to appendix?}

\subsection{Observation Model}
\todo{Complete this, explain better, figures...}
In context of this project, the most important criteria of selecting a pose is based on the observability of small joint movements by the available sensors. Each of these sensors are modelled as an observation model, thus it is possible to examine the strength and direction of observable dimensions of each sensor at a given pose by reaching that particular pose and inducing small joint movements (mimicing possible joint errors).

For the scope of this project, only the two cameras onboard the Nao robot were modelled. In addition, assumptions were made regarding the placement of calibration patterns.

\subsubsection{Camera observation model}
\todo{diagram of grid projection, etc stuff}

This model is comprised of following elements, it's state is updated whenever a new pose is submitted.
\begin{itemize}
	\item CameraMatrix object (\todo{refer nao architecture?}).
	\subitem This stores intrinsic as well as camera-to-ground matrix.
	\item Ground grid. This is a grid of points on the ground plane.
	\subitem The grid moves so that it is observable by each camera when the model is updated.
	\item Support foot, observable joints (for each camera and at each support foot). \todo{explain why single leg support is useful.}
	\item The observation space of small movement by the camera's sensor (2D) is assumed to be X, Y translations and Z rotations.
	\subitem Although six degrees of freedom is possible to be observed by a camera using two images or point-to-point correspondance sets, in practice, only x, y translations and z- rotation was dominant. \todo{how did I determine this? :P } Thus this is a simplification of the actual system.
\end{itemize}

The process of obtaining observability of a given pose for each joint is as follows: \todo{write as psuedocode?}
\begin{itemize}
	\item The CameraMatrix is updated based on the set of joint angles and support foot (Mentioned as "Raw Pose" in the code).
	\item Translate + Rotate the ground grid so that the camera can see the grid.
	\item Obtain projection of the ground grid in Camera image plane (2D). This is referred as "baseline points".
	\item For-each joint, add a \(\delta\theta\) angle and obtain projection of the ground points in Camera image plane (2D).
	\subitem Using correspondance of the baseline points and latter obtained points, the movement of camera sensor plane (x, y, rotation in Z axis) is obtained using an optimization method and stored.
	\item At the end of evaluation, an object comprising of observation values as well as whether movement of a joint was observed is returned.
\end{itemize}

\todo{Nao camera chain from ground..}

\subsubsection{Extending Observation model}

Based on the technique employed for the camera model, it is possible to model other sensors as well. The inputs would be joint angles, support foot and information of observable joints by the given sensor.
Output would be similar to camera observation output, in fact the same type of object can be returned albeit a possible different number of observed dimensions. Usage of C++ templates made this possible without unnessesary usage of inheritance traits. \todo{ rewrite clearly}

Once the sensitivities for a pose is returned for each sensor under consideration, they are written to a file with pose ID (generated in the previous step), sensitivity values for each joint. 
\subsection{Criteria for evaluating observability}

When a series of measurements is organized in the form of a vector, it gives the possibility to understand if two sets of measurements are "nearby", or at same direction, etc. \todo{maybe move this to lit-review?}

By applying this ability, it is possible to conclude if two observations are "similar". Thus if two (or more) observations for different joint movements at the same base pose is similar, there exist an ambiguity, as it isn't possible to seperately identify which joint caused the particular observation. Thus avoiding poses with such similar observations for multiple joints is beneficial as the solving the equations by means of iterative solver needs as much as orthogonality between observation vectors as possible.
\todo{ Back up this with facts? dummy dtaa set? }

\subsection{Extracting optimal poses}

Considering the above mentioned need for dissimilar observation vectors for each joint observation for a given pose, and other factors, it was evident that filtering the poses with a cost function would be beneficial.

\subsubsection{Cost function \& weights}

\todo{define the cost function and other info}
\todo{ Explain the situation of angle}

\subsubsection{Determining calibration pattern position}
\todo{Not implemented yet}

\section{Calibration Process}
A modified version of the RC2018 calibration tool is used for this step. In exact terms, the ability to feed poses, workflow and internals of the calibration pipeline was altered.

Further information about the tools and software is available in the team research report and the code release. \todo{cite when TRR is released}
%%\section{Testing and evaluation of calibration poses and process}

\chapter{Testing and Evaluation}
\todo{Intro para}
\section{Tests for code quality}
\todo{Mention unit tests, etc}
\section{Calibration tests}
\todo{Intro para}
\subsection{Simulation: Entire ground plane as a calibration pattern}
\todo{Explain why}
\todo{Data, randomly induced errors, individually induced errors}
\subsection{Simulation: Actual calibration process}
\todo{Explain why}
\todo{Data, randomly induced errors, individually induced errors}
\subsection{Real?: Actual calibration process}
\todo{if above succeed, try on real robots}

\chapter{Conclusion and future work}
\todo{Complete this}
%%% include your text here %%%

\end{document}
